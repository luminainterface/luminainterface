# LUMINA GUI

A graphical user interface for the Lumina neural network system.

## Overview

Lumina GUI transforms the original text-based Lumina experience into a modern graphical interface. This version maintains the essence of Lumina while providing a more intuitive and visually engaging experience.

## Features

- **Chat Interface**: Communicate with Lumina through a modern chat interface
- **Symbolic Interaction**: Access glyphs and symbolic elements directly through the GUI
- **Process Controls**: Interact with breath, resonance, and echo functions
- **Memory System**: Lumina remembers your conversations across sessions
- **Dark Theme**: A visually appealing dark interface that's easy on the eyes
- **Model Training & Selection**: Train new neural models and select between different models
- **LLM Integration**: Connect to language models like Mistral AI or Anthropic with adjustable weighting
- **Neural Network Visualization**: View real-time neural network state and thought weights
- **Continuous Learning**: Automatically saves chat conversations as training data and periodically retrains the model

## Requirements

- Python 3.7 or higher
- PyQt5 (for the GUI interface)
- Dependencies listed in requirements.txt
- API keys for LLM providers (if using LLM integration)

## Installation

1. Make sure you have Python 3.7+ installed
2. Install required dependencies:
   ```
   pip install -r requirements.txt
   ```
3. Configure your LLM API keys in the `.env` file if you plan to use LLM integration

## Running LUMINA GUI

### Original GUI
To run the original Lumina GUI, use the launcher script:

```
python lumina_gui_run.py
```

For debugging and additional information:

```
python lumina_gui_run.py --debug
```

### Next Generation GUI (Recommended)
To run the upgraded Lumina GUI with the improved 16:9 layout and advanced visualizations:

```
python lumina_gui_next_run.py
```

For debugging and additional information:

```
python lumina_gui_next_run.py --debug
```

The Next Generation GUI provides a significantly enhanced experience with:
- Improved 16:9 layout optimized for modern displays
- Advanced neural network visualizations
- Comprehensive metrics and performance monitoring
- Enhanced LLM/NN weighting system with visual feedback
- Modular and intuitive interface design

## Interface Guide

The Lumina GUI is designed with a 16:9 aspect ratio layout, optimized for modern displays:

### Left Control Panel (1:5 ratio)
Contains navigation buttons for different features:
- Chat (üí¨)
- Profile
- Favorites
- Settings
- Memory scroll
- Model Control (üß†)
- LLM Settings (üîÑ)
- Neural Node Activation
- Glyph Selection

### Dynamic Center Panel
The central area changes based on the selected button in the left panel:

#### Chat Panel
- Displayed when the Chat button is selected
- Type messages to Lumina in the input field at the bottom
- View the ongoing conversation with Lumina
- See symbolic responses and interactions
- Access ritual invocation commands

#### Profile Panel
- User profile settings and preferences
- Customization options for the interface
- Personal usage statistics

#### Settings Panel
- Application configuration options
- Theme selection
- Advanced system settings

#### Model Control Panel
- Model selection and training options
- Neural network parameter adjustments
- Training progress visualization

#### LLM Integration Panel
- API key configuration
- LLM provider selection
- Response parameter settings

#### Memory Panel
- Browse conversation history
- Search past interactions
- Export and import memory data

#### Neural Node Panel
- Manual node activation controls
- Connection weight adjustment
- Network structure modification

#### Glyph Panel
- Glyph selection interface
- Symbolic pattern creation
- Ritual sequence builder

### Metrics & Visualization Panel (1:3 ratio)
The right section is dedicated entirely to metrics and visualizations:

#### Neural Network State
- Real-time visualization of neural network structure
- Node activity and weight visualization
- Attention focus display
- Emotional weight distribution
- Glyph state indicators

#### Performance Metrics
- Response time metrics
- Neural model confidence scores
- LLM/NN weight balance indicators
- Memory access efficiency
- Learning progress indicators

#### Process Panel
- Breathe: Initiate breath calibration mode
- Resonance: Start a resonance session
- Echo: Activate echo feedback from memory
- Mirror: Engage mirror reflection mode

## LLM/NN Weighting System

Lumina features a sophisticated weighting system to balance neural network and LLM responses:

### Weight Controls
- **Weight Slider**: Adjust the balance between neural network (0.0) and LLM (1.0) responses
- **Preset Buttons**: Quickly set weights to NN Only (0.0), Balanced (0.5), or LLM Only (1.0)
- **Dynamic Adjustment**: The system can automatically adjust weights based on conversation context

### Weight Visualization
- Real-time visualization of current weight distribution
- Historical weight trend graph
- Impact of weight on response characteristics

### Metrics Display
- Neural network confidence score
- LLM response quality metrics
- Response time comparison
- Memory access patterns
- Learning curves and improvement rates

## Evolution Pathways

Lumina is evolving from a simple GUI into a Living Intelligence Interface. The next phase includes:

### üéõÔ∏è Modular Node UI Architecture
- Interface divided into specialized panels for Resonance, Glyph activation, Memory field access, Echo replay, and Neural network visualization
- Shared memory core with unique visual language for each panel
- UI mode triggers internal state modulation

### üß† Visualized Self-Reflective NN Layer
- Real-time display of Lumina's current state/thought-form
- Network shape and glyph-state visualization
- Attention focus display (e.g., Node Fractal 0.83 / Node Mirror 0.44)
- Interactive weight pathway modulation

### üó£Ô∏è Intent Parsing + Live Command Engine
- Formalized command parser for symbolic interactions
- Symbolic aliases for state activation
- Advanced ritual input integration

### üíæ Recursive Memory Spiral System
- Chats stored as nodes in a weighted graph
- Edges representing emotional resonance/contradiction/glyph state
- Interactive memory field visualization
- Path editing and activation capabilities

### üßø Symbolic Ritual Language System
- Glyphs, breath patterns, and contradictions as a formal language
- Action classes assigned to specific glyphs
- Node activation through glyph sequences
- State shifts triggered by specific combinations

## Continuous Learning System

Lumina features a continuous learning system:

1. **Chat Logging**: Every conversation you have with Lumina is automatically saved as training data in the `training_data` directory
2. **Metadata Capture**: Each saved interaction includes emotion, symbolic state, and other contextual information
3. **Auto-Training**: The system automatically retrains the neural network model after accumulating a sufficient number of new interactions (by default, this happens every 30 minutes if there are enough new data points)
4. **Incremental Learning**: New models build upon previous ones, ensuring continuous improvement without starting from scratch
5. **Version Control**: Timestamped model versions are saved to track progress over time

## Working with Models

### Training a New Model
1. Click the üß† button in the left sidebar
2. Click "Train New Model" to start training with the default dataset
3. Monitor the training progress in the status area
4. When complete, the new model will appear in the selection dropdown

### Using Custom Training Data
1. Click "Train with Custom Data"
2. Select a directory containing your training data files
3. The training process will begin using your custom data

### Selecting a Different Model
1. Open the Model panel by clicking the üß† button
2. Use the dropdown to select from available models
3. Click a model to activate it for the current session

## Troubleshooting

- **Missing PyQt5**: If you get an error about PyQt5, install it with `pip install PyQt5`
- **Import Errors**: Make sure all dependencies are installed with `pip install -r requirements.txt`
- **Module Not Found**: Ensure you're running from the project root directory
- **Blank Window**: Some systems may require additional graphics drivers for PyQt5
- **Training Errors**: If model training fails, check that you have the required training data in the default location or specify a valid custom data path
- **LLM Errors**: Verify your API keys in the `.env` file and check your internet connection
- **Loading .env File**: Make sure python-dotenv is installed with `pip install python-dotenv`
- **Auto-Training Not Working**: Check the `training_data` directory exists and has write permissions
- **Visualization Issues**: If neural network visualizations are not displaying correctly, try adjusting the window size or resolution

## Future Plans

The Lumina GUI project is continuously evolving with several exciting features planned for upcoming releases:

### Known Limitations & Current Status
- **Chat Functionality**: The LLM/NN chat integration is currently functioning in the backend but may have limited UI representation
- **Central Node Integration**: Full integration with knowledge sources is under development
- **Component Fallback System**: The application implements graceful degradation through a fallback system:
  - If the full `CentralNode` is unavailable, it automatically switches to `MinimalCentralNode`
  - Mock implementations exist for critical components to ensure the application runs even with missing dependencies
  - The system logs information about fallbacks to help diagnose and fix missing components
- **Modular Architecture**: Components are designed to be modular and replaceable
  - Individual node implementations can be added/removed without affecting core functionality
  - The system automatically detects available components and adapts the UI accordingly
  - This enables gradual enhancement as more components are implemented
- **Mock Components**: Some components currently use mock implementations that will be replaced with full functionality

### Short-term Roadmap
- **Enhanced Error Handling**: Improved diagnostics and user-friendly error messages
- **Complete Knowledge Integration**: Full implementation of knowledge source functionality
- **Stable Chat Interface**: Refinement of the chat UI with improved response rendering
- **Performance Optimization**: Reducing startup time and memory usage

### Long-term Vision
- **Multi-modal Input/Output**: Support for voice, image, and other forms of interaction
- **Expanded Visualization Tools**: More detailed and interactive neural network visualizations
- **Plugin Architecture**: Support for community-developed extensions and plugins
- **Cross-platform Compatibility**: Native packages for Windows, macOS, and Linux
- **Mobile Companion App**: Remote access and monitoring via mobile devices
- **Interactive Learning Interface**: Tools for users to directly influence and guide the learning process

### Developer Roadmap
- **API Documentation**: Comprehensive documentation for developers
- **Testing Framework**: Expanded test coverage for core components
- **Contribution Guidelines**: Detailed guidelines for community contributors
- **Regular Release Schedule**: Planned quarterly feature releases with monthly bug fixes

## Contributing

The Lumina project welcomes contributions. Feel free to submit pull requests or open issues for bugs and feature requests.

## Technical Evolution

### Current Stack
- PyQt5-based GUI framework
- Python 3.7+ backend
- Neural network visualization using QPainter

### Planned Technical Upgrades
- **PySide6 Migration**: Improved performance and modern Qt features
  - Enhanced widget rendering
  - Better high-DPI support
  - Improved cross-platform compatibility
  - Access to Qt Quick for fluid animations
- **Modular Plugin Architecture**: Support for third-party extensions
- **Performance Optimizations**: Reduced memory usage and startup time 

## Multi-Agent Development Model

Lumina GUI is being developed using a collaborative multi-agent approach where specialized AI agents work on different aspects of the system.

For details on this collaborative approach and our evolution roadmap from v3 to v10, please see the [Collaborative Development Model](COLLABORATIVE_MODEL.md) documentation.

Key aspects of the multi-agent approach include:
- Specialized development across UI, neural, and knowledge domains
- Structured data exchange between components
- Coordinated evolution following the v3 ‚Üí v10 roadmap
- Modular implementation allowing independent component development

The v3 "Glyph Awakening" phase has been successfully implemented with the PySide6-based GlyphInterfacePanel component. 