# Docker Compose configuration for Lumina system (V2)
# --------------------------------------------

version: '3.8'

name: lumina-system

networks:
  backend:
    driver: bridge

services:
  redis:
    image: redis:7.2-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    command: redis-server --appendonly yes --save 900 1 --save 300 10
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 3
    restart: unless-stopped
    networks:
      - backend

  # Busybox that keeps Streams alive (creates groups on first boot)
  redis-streams-init:
    image: busybox:1.36
    command: sh -c "sleep infinity"
    depends_on:
      redis:
        condition: service_healthy
    networks:
      - backend

  redis-exporter:
    image: oliver006/redis_exporter:latest
    command: --redis.addr=redis://redis:6379
    ports:
      - "9121:9121"
    depends_on:
      - redis

  neo4j:
    image: neo4j:5.13.0
    ports:
      - "7474:7474"  # HTTP
      - "7687:7687"  # Bolt
    environment:
      - NEO4J_AUTH=neo4j/password
      - NEO4J_dbms_memory_pagecache_size=1G
      - NEO4J_dbms_memory_heap_initial__size=1G
      - NEO4J_dbms_memory_heap_max__size=1G
      - NEO4J_ACCEPT_LICENSE_AGREEMENT=yes
      - NEO4J_apoc_export_file_enabled=true
      - NEO4J_apoc_import_file_enabled=true
      - NEO4J_apoc_import_file_use__neo4j__config=true
      - NEO4J_dbms_security_procedures_unrestricted=apoc.*
    volumes:
      - neo4j_data:/data
      - neo4j_logs:/logs
      - neo4j_plugins:/plugins
    healthcheck:
      test: ["CMD-SHELL", "wget --no-verbose --tries=1 --spider http://localhost:7474 || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    restart: unless-stopped
    networks:
      - backend

  qdrant:
    image: qdrant/qdrant:latest
    volumes:
      - qdrant_data:/qdrant/storage
    ports:
      - "6333:6333"
      - "6334:6334"
    healthcheck:
      test: ["CMD-SHELL", "timeout 1 bash -c '>/dev/tcp/localhost/6333'"]
      interval: 10s
      timeout: 3s
      retries: 3

  ollama:
    image: ollama/ollama:latest
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    networks:
      - backend
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/api/tags"]
      interval: 30s
      timeout: 5s
      retries: 3
    restart: unless-stopped

  prometheus:
    image: prom/prometheus:latest
    volumes:
      - ./services/prometheus:/etc/prometheus
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/usr/share/prometheus/console_libraries'
      - '--web.console.templates=/usr/share/prometheus/consoles'
    ports:
      - "9090:9090"
    depends_on:
      - redis-exporter

  grafana:
    image: grafana/grafana:10.0.3
    ports:
      - "3000:3000"
    volumes:
      - grafana_data:/var/lib/grafana
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_USERS_ALLOW_SIGN_UP=false
    depends_on:
      - prometheus

  promtail:
    image: grafana/promtail:latest
    volumes:
      - ./logs:/var/log/app
      - ./promtail-config.yml:/etc/promtail/promtail-config.yml
    command: -config.file=/etc/promtail/promtail-config.yml
    networks:
      - backend
    restart: unless-stopped

  loki:
    image: grafana/loki:2.8.2
    ports:
      - "3100:3100"
    command: -config.file=/etc/loki/local-config.yaml
    networks:
      - backend
    restart: unless-stopped

  jaeger:
    image: jaegertracing/all-in-one:1.48
    ports:
      - "16686:16686"
      - "6831:6831/udp"
      - "6832:6832/udp"
      - "5778:5778"
      - "14268:14268"
      - "14250:14250"
      - "9411:9411"
    networks:
      - backend
    restart: unless-stopped

  alertmanager:
    image: prom/alertmanager:latest
    ports:
      - "9093:9093"
    networks:
      - backend
    restart: unless-stopped

  auditor:
    build:
      context: ./services/auditor
      dockerfile: Dockerfile
    ports:
      - "8811:8811"
    networks:
      - backend
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8811/health"]
      interval: 30s
      timeout: 5s
      retries: 3
    depends_on:
      - redis

  debugger:
    build:
      context: ./services/debugger
      dockerfile: Dockerfile
    ports:
      - "8814:8814"
    networks:
      - backend
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8814/health"]
      interval: 30s
      timeout: 5s
      retries: 3
    depends_on:
      - redis

  drift-exporter:
    build:
      context: ./services/drift-exporter
      dockerfile: Dockerfile
    ports:
      - "8816:8816"
    networks:
      - backend
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8816/health"]
      interval: 30s
      timeout: 5s
      retries: 3
    depends_on:
      - redis

  monitoring:
    build:
      context: ./services/monitoring
      dockerfile: Dockerfile
    ports:
      - "8824:8824"
    networks:
      - backend
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8824/health"]
      interval: 30s
      timeout: 5s
      retries: 3
    depends_on:
      - redis

  crawler:
    build:
      context: .
      dockerfile: services/crawler/Dockerfile
    ports:
      - "8000:8000"
    environment:
      - REDIS_URL=redis://redis:6379
      - QDRANT_URL=http://qdrant:6333
      - GRAPH_API_URL=http://graph-api:8829
      - CONCEPT_DICT_URL=http://concept-dict:8000
      - BUS_STREAM=ingest.crawl
      - CRAWL_REQ_STREAM=crawl_request
      - MAX_DEPTH=3
      - MAX_LINKS_PER_PAGE=50
      - CACHE_TTL=3600
      - MIN_RELEVANCE_SCORE=0.5
      - MAX_CONCURRENT_CRAWLS=10
      - DEAD_LETTER_STREAM=dlq.crawler
      - LOG_LEVEL=INFO
    depends_on:
      redis:
        condition: service_healthy
      concept-dict:
        condition: service_healthy
    networks:
      - backend
    restart: unless-stopped

  event-mux:
    build:
      context: ./services/event-mux
      dockerfile: Dockerfile
    ports:
      - "8817:8817"
    networks:
      - backend
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8817/health"]
      interval: 30s
      timeout: 5s
      retries: 3
    depends_on:
      - redis

  batch-embedder:
    build:
      context: .
      dockerfile: services/batch-embedder/Dockerfile
    ports:
      - "8709:8709"
    environment:
      - REDIS_URL=redis://redis:6379
      - EMBED_MODEL=all-MiniLM-L6-v2
      - CONCEPT_TRAINER_URL=http://concept-trainer-growable:8905
    depends_on:
      redis:
        condition: service_healthy
      concept-trainer-growable:
        condition: service_started
    networks:
      - backend
    restart: unless-stopped

  output-engine:
    build:
      context: ./services/output-engine
      dockerfile: Dockerfile
    ports:
      - "9000:9000"
    environment:
      - OLLAMA_URL=http://ollama:11434
      - OUTPUT_ENGINE_API_KEY=changeme
      - TEMP_DIR=/tmp/output-engine
      - REDIS_URL=redis://redis:6379
      - CONCEPT_STREAM=concept.new
      - GENERATION_STREAM=output.generated
      - CONCEPT_DICT_URL=http://concept-dict:8828
    volumes:
      - output-engine-temp:/tmp/output-engine
      - adapters_data:/adapters
    depends_on:
      redis:
        condition: service_healthy
      concept-dict:
        condition: service_started
      ollama:
        condition: service_started
    networks:
      - backend
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/health"]
      interval: 30s
      timeout: 5s
      retries: 3
    restart: unless-stopped

  concept-dict:
    build:
      context: .
      dockerfile: services/concept-dictionary/Dockerfile
    ports:
      - "8828:8000"
    environment:
      - REDIS_URL=redis://redis:6379
      - NEO4J_URL=bolt://neo4j:7687
      - EMBEDDING_DIM=384
      - EMBEDDING_MULTI_MODULE=false
    depends_on:
      redis:
        condition: service_healthy
      neo4j:
        condition: service_healthy
    networks:
      - backend
    restart: unless-stopped

  graph-api:
    build:
      context: ./services/graph-api
      dockerfile: Dockerfile
    ports:
      - "8829:8829"
    networks:
      - backend
    restart: unless-stopped

  concept-trainer:
    image: alpine
    command: tail -f /dev/null
    ports:
      - "8831:8831"
    networks:
      - backend
    restart: unless-stopped

  concept-trainer-growable:
    build:
      context: .
      dockerfile: services/concept-trainer-growable/Dockerfile
    ports:
      - "8905:8905"
    environment:
      - REDIS_URL=redis://redis:6379
      - DICT_URL=http://concept-dict:8000
      - QDRANT_URL=http://qdrant:6333
      - DEVICE=${DEVICE:-cpu}
      - MODEL_DATA_DIR=/app/data
    volumes:
      - ./services/concept-trainer-growable/data:/app/data
      - ./services/concept-trainer-growable/training_data:/app/training_data
    depends_on:
      redis:
        condition: service_healthy
      concept-dict:
        condition: service_healthy
    networks:
      - backend
    restart: unless-stopped

  concept-trainer-embedder:
    image: alpine
    command: tail -f /dev/null
    ports:
      - "8833:8833"
    networks:
      - backend
    restart: unless-stopped

  concept-trainer-embedder-growable:
    image: alpine
    command: tail -f /dev/null
    ports:
      - "8834:8834"
    networks:
      - backend
    restart: unless-stopped

  concept-analytics:
    build:
      context: ./services/concept-analytics
      dockerfile: Dockerfile
    ports:
      - "8835:8835"
    networks:
      - backend
    restart: unless-stopped

  concept-analyzer:
    build:
      context: ./services/concept-analyzer
      dockerfile: Dockerfile
    ports:
      - "8836:8836"
    networks:
      - backend
    restart: unless-stopped

  learning-graph:
    build:
      context: ./services/learning-graph
      dockerfile: Dockerfile
    ports:
      - "8837:8837"
    networks:
      - backend
    restart: unless-stopped

  dual-chat-router:
    build:
      context: ./services/dual-chat-router
      dockerfile: Dockerfile
    ports:
      - "8838:8838"
    networks:
      - backend
    restart: unless-stopped

  masterchat-core:
    build:
      context: ./services/masterchat-core
      dockerfile: Dockerfile
    ports:
      - "8839:8839"
    environment:
      - REDIS_URL=redis://redis:6379
    volumes:
      - adapters_data:/adapters
    networks:
      - backend
    restart: unless-stopped

# --- Disabled: No directory or Dockerfile found for masterchat-llm ---
# masterchat-llm:
#   build:
#     context: ./services/masterchat-llm
#     dockerfile: Dockerfile
#   ports:
#     - "8840:8840"
#   networks:
#     - backend
#   restart: unless-stopped

# --- UI service intentionally disabled for now ---
# ui:
#   build:
#     context: ./services/ui
#     dockerfile: Dockerfile
#   networks:
#     - backend
#   ports:
#     - "80:80"
#   restart: unless-stopped

  pdf-trainer:
    build:
      context: ./services/pdf-trainer
      dockerfile: Dockerfile
    ports:
      - "8841:8841"
    networks:
      - backend
    restart: unless-stopped

  retrain-listener:
    build:
      context: .
      dockerfile: services/retrain-listener/Dockerfile
    environment:
      - REDIS_URL=redis://redis:6379
      - TRAIN_URL=http://batch-embedder:8709/train_batch
      - SOURCE_STREAM=output.generated
      - BATCH_SIZE=64
    ports:
      - "8000:8000"
    depends_on:
      redis:
        condition: service_healthy
      batch-embedder:
        condition: service_healthy
    networks:
      - backend
    restart: unless-stopped

  graph-concept-adapter:
    build:
      context: ./services/graph-concept-adapter
      dockerfile: Dockerfile
    ports:
      - "8842:8842"
    networks:
      - backend
    restart: unless-stopped

# --- Disabled: No directory or Dockerfile found for data-analyzer ---
# data-analyzer:
#   build:
#     context: ./services/data-analyzer
#     dockerfile: Dockerfile
#   ports:
#     - "8843:8843"
#   networks:
#     - backend
#   restart: unless-stopped

# --- Disabled: No directory or Dockerfile found for log-embedding-worker ---
# log-embedding-worker:
#   build:
#     context: ./services/log-embedding-worker
#     dockerfile: Dockerfile
#   ports:
#     - "8846:8846"
#   networks:
#     - backend
#   restart: unless-stopped

# --- Disabled: No directory or Dockerfile found for learning-path-optimizer ---
# learning-path-optimizer:
#   build:
#     context: ./services/learning-path-optimizer
#     dockerfile: Dockerfile
#   ports:
#     - "8844:8844"
#   networks:
#     - backend
#   restart: unless-stopped

# --- Disabled: No directory or Dockerfile found for trend-analyzer ---
# trend-analyzer:
#   build:
#     context: ./services/trend-analyzer
#     dockerfile: Dockerfile
#   ports:
#     - "8845:8845"
#   networks:
#     - backend
#   restart: unless-stopped

volumes:
  redis_data:
    driver: local
  neo4j_data:
  neo4j_logs:
  neo4j_plugins:
  prometheus_data:
    driver: local
  grafana_data:
    driver: local
  qdrant_data:
    driver: local
  ollama_data:
  output-engine-temp:
  adapters_data:
    driver: local

# Remaining services (not yet added) in the stack:
# --------------------------------------------
# (Core Services)
# – concept-dict
# – graph-api
# – concept-trainer (and its growable variants)
# – concept-trainer-embedder (and its growable variants, including gpu variants)
# – concept-trainer-embedder-growable-gpu-{1,…, 230} (if applicable)
# – concept-analytics
# – concept-analyzer
# – learning-graph
# (Chat & LLM)
# – dual-chat-router
# – masterchat-core
# (UI)
# – ui 
# – ui 